{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(os.listdir(\"archive/cell_images/cell_images\"))\n",
    "\n",
    "base_dir = 'archive/cell_images/cell_images/'\n",
    "work_dir = 'work/'\n",
    "#os.mkdir(work_dir)\n",
    "\n",
    "base_dir_A = 'archive/cell_images/cell_images/Parasitized/' \n",
    "base_dir_B = 'archive/cell_images/cell_images/Uninfected/'\n",
    "\n",
    "work_dir_A = 'work/A/'\n",
    "#os.mkdir(work_dir_A)\n",
    "work_dir_B = 'work/B/'\n",
    "#os.mkdir(work_dir_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New directories for train, validation, and test created\n",
      "Train, Validation, and Test folders made for both A and B datasets\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(work_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(work_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(work_dir, 'test')\n",
    "#os.mkdir(test_dir)\n",
    "\n",
    "print(\"New directories for train, validation, and test created\")\n",
    "train_pos_dir = os.path.join(train_dir, 'pos')\n",
    "#os.mkdir(train_pos_dir)\n",
    "train_neg_dir = os.path.join(train_dir, 'neg')\n",
    "#os.mkdir(train_neg_dir)\n",
    "\n",
    "validation_pos_dir = os.path.join(validation_dir, 'pos')\n",
    "#os.mkdir(validation_pos_dir)\n",
    "validation_neg_dir = os.path.join(validation_dir, 'neg')\n",
    "#os.mkdir(validation_neg_dir)\n",
    "\n",
    "test_pos_dir = os.path.join(test_dir, 'pos')\n",
    "#os.mkdir(test_pos_dir)\n",
    "test_neg_dir = os.path.join(test_dir, 'neg')\n",
    "#os.mkdir(test_neg_dir)\n",
    "\n",
    "print(\"Train, Validation, and Test folders made for both A and B datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images for both categories have been copied to working directories, renamed to A & B + num\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "      \n",
    "for filename in os.listdir(base_dir_A): \n",
    "    dst =\"pos\" + str(i) + \".jpg\"\n",
    "    src =base_dir_A + filename \n",
    "    dst =work_dir_A + dst \n",
    "          \n",
    "       # rename() function will \n",
    "       # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    i += 1\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for filename in os.listdir(base_dir_B): \n",
    "    dst =\"neg\" + str(j) + \".jpg\"\n",
    "    src =base_dir_B + filename \n",
    "    dst =work_dir_B + dst \n",
    "          \n",
    "    # rename() function will \n",
    "    # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    j += 1       \n",
    "        \n",
    "print(\"Images for both categories have been copied to working directories, renamed to A & B + num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['pos{}.jpg'.format(i) for i in range(3000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(train_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(3000, 4000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(validation_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(4000, 4500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(test_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, and test datasets split and ready for use\n",
      "total training pos images: 3000\n",
      "total training neg images: 3000\n",
      "total validation pos images: 1000\n",
      "total validation neg images: 1000\n",
      "total test pos images: 500\n",
      "total test neg images: 500\n"
     ]
    }
   ],
   "source": [
    "fnames = ['neg{}.jpg'.format(i) for i in range(3000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(train_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(3000, 4000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(validation_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(4000, 4500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(test_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Train, validation, and test datasets split and ready for use\")\n",
    "print('total training pos images:', len(os.listdir(train_pos_dir)))\n",
    "print('total training neg images:', len(os.listdir(train_neg_dir)))\n",
    "print('total validation pos images:', len(os.listdir(validation_pos_dir)))\n",
    "print('total validation neg images:', len(os.listdir(validation_neg_dir)))\n",
    "print('total test pos images:', len(os.listdir(test_pos_dir)))\n",
    "print('total test neg images:', len(os.listdir(test_neg_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4020 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory= train_dir,             \n",
    "                                                     target_size=(128, 128),\n",
    "                                                     class_mode='binary',\n",
    "                                                     subset='training',\n",
    "                                                    shuffle=True,\n",
    "                                                     batch_size=32\n",
    "                                 )\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(directory= validation_dir,\n",
    "                                                      target_size=(128, 128),\n",
    "                                                     class_mode='binary',\n",
    "                                                           shuffle = True,\n",
    "                                                     subset='validation',\n",
    "                                                     batch_size=32,\n",
    "                                                    \n",
    "                                                     )\n",
    "\n",
    "\n",
    "classes = ['Parasitized', 'Uninfected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,172,225\n",
      "Trainable params: 147,841\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG19(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(256,activation='relu'))\n",
    "vgg_model.add(Dense(64,activation='relu'))\n",
    "vgg_model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999)\n",
    "vgg_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kotla\\AppData\\Local\\Temp\\ipykernel_34148\\2786986023.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  vgg_history = vgg_model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 166s 1s/step - loss: 0.2496 - accuracy: 0.9032 - val_loss: 0.1406 - val_accuracy: 0.9606\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 165s 1s/step - loss: 0.2334 - accuracy: 0.9119 - val_loss: 0.1893 - val_accuracy: 0.9364\n"
     ]
    }
   ],
   "source": [
    "vgg_history = vgg_model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              epochs=10,\n",
    "                              validation_steps = len(valid_generator),\n",
    "                                      validation_data = valid_generator,\n",
    "                              callbacks = [early_stop],\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save('vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "[[0.23628019]]\n",
      "The image classified is Uninfected\n"
     ]
    }
   ],
   "source": [
    "#predict on specific image\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "#predict on specific image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = image.load_img('archive/cell_images/cell_images/Uninfected/C101P62ThinF_IMG_20150918_151006_cell_17.png', target_size=(128, 128))\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "img = image.img_to_array(img)\n",
    "img = img/255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "prediction = vgg_model.predict(img)\n",
    "print(prediction)\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print(\"The image classified is Parasitized\")\n",
    "else:\n",
    "    print(\"The image classified is Uninfected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
